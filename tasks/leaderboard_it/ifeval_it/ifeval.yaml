task: itabench_leaderboard_ifeval_it

## DATASET ##
dataset_name: null
dataset_path: MinervaV2/ifeval_ita_fixed
test_split: train

## PROMPT & ANSWERING ##
output_type: generate_until
num_fewshot: 0

#doc_to_text: translated_prompt
doc_to_text: prompt

doc_to_target: 0
generation_kwargs:
  until: []
  do_sample: false
  temperature: 0.0
  max_gen_toks: 1280
process_results: !function utils.process_results
fewshot_config:
  sampler: first_n

## METRICS ##
metric_list:
  - metric: prompt_level_strict_acc
    aggregation: mean
    higher_is_better: true
  - metric: inst_level_strict_acc
    aggregation: !function utils.agg_inst_level_acc
    higher_is_better: true
  - metric: prompt_level_loose_acc
    aggregation: mean
    higher_is_better: true
  - metric: inst_level_loose_acc
    aggregation: !function utils.agg_inst_level_acc
    higher_is_better: true

## MISC ##
metadata:
  version: 1.0

